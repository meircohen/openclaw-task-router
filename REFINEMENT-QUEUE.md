# Quality Refinement Queue

## Overview

The Quality Refinement Queue implements a **junior/senior developer workflow** for the OpenClaw Task Router. When tasks are executed on cheaper/faster models (Haiku, GPT-4.1-mini, local Ollama), they get added to a "refinement queue." When expensive subscription backends (Claude Code, Codex) are idle — no active tasks, no pending requests — they automatically pick up queued items and re-execute them at higher quality.

## The Analogy

Think of it like a development team:

- **Junior developers** (cheap, fast models) implement features quickly and push code
- **Senior developers** (expensive, high-quality models) review and improve the code when they have bandwidth
- The result: fast initial delivery with automatic quality improvement over time

This gives us:
- ✅ **Fast responses** — users get immediate results from cheap models
- ✅ **High quality** — expensive models refine the output when idle
- ✅ **Cost efficiency** — expensive models only run when we have spare capacity
- ✅ **Learning loops** — we can measure how much refinement actually improves results

## How It Works

### 1. Task Completion → Queue Decision

After a task completes on a cheap backend (`local`, `api` with cheap models), the system decides whether to queue it for refinement:

**Queue if:**
- Complexity >= 3 (configurable `minComplexityToQueue`)
- Task type is code-generating or analysis (not pure queries)
- Original quality score < 90% (if available)
- Backend was "cheap" (local Ollama, Haiku, etc.)

**Skip if:**
- Too simple (complexity <= 2)
- Pure query/search task (no code output)
- Already executed on expensive backend
- Original result scored very highly

### 2. Priority Calculation

Items are prioritized 1-10 based on:
- **Base priority** = task complexity (3-10)
- **+1 boost** for code-generating tasks (`type: 'code'` or `type: 'implementation'`)
- **+1 boost** for tasks with file outputs (likely code)
- **+1 boost** for complex analysis tasks (type = 'analysis' + complexity >= 6)

Higher priority = refined sooner when backends are idle.

### 3. Idle Detection & Refinement

Every 30 seconds (configurable), the system checks:
- Are Claude Code or Codex backends idle?
- No tasks in main queue
- No active executions
- Circuit breaker is CLOSED (backend healthy)
- Not rate-limited

If idle → pick highest priority refinement item → execute refinement.

### 4. Refinement Execution

The refinement prompt includes:
```
Review and improve this code that was generated by [originalModel].

Original task: [description]
Original output: [summary]

Make it production-quality:
- Better error handling and edge cases
- Cleaner, more maintainable code  
- More robust validation
- Better naming and documentation

Only change what genuinely improves quality — don't refactor for the sake of it.
```

### 5. Result Comparison & Learning

After refinement:
- Compare original vs refined output (quality score 0-100)
- Update average improvement statistics
- Track tokens saved by fast-first approach
- Log which model combinations work best

## Data Structure

The queue maintains state in `data/refinement-queue.json`:

```json
{
  "queue": [
    {
      "id": "ref_abc123",
      "originalTaskId": "rt_xyz789", 
      "description": "write unit tests for auth module",
      "originalBackend": "local",
      "originalModel": "ollama/phi3:mini",
      "originalResult": {
        "files": ["test-auth.js"],
        "summary": "Generated unit tests for authentication",
        "output": "..."
      },
      "originalComplexity": 5,
      "originalTokens": 2000,
      "originalDuration": 8000,
      "queuedAt": "2026-02-19T10:30:00Z",
      "status": "pending",
      "priority": 6,
      "refinementBackend": null,
      "refinementResult": null,
      "refinedAt": null,
      "improvementScore": null
    }
  ],
  "completed": [
    // Completed/skipped refinements with full results
  ],
  "stats": {
    "totalRefined": 42,
    "avgImprovementScore": 73.5,
    "tokensSaved": 125000
  }
}
```

## Configuration

In `config.json`:

```json
{
  "refinementQueue": {
    "enabled": true,
    "maxQueueSize": 50,
    "minComplexityToQueue": 3,
    "idleCheckIntervalMs": 30000,
    "preferredBackend": "claudeCode", 
    "fallbackBackend": "codex",
    "maxRefinementsPerHour": 5,
    "skipIfOriginalScoreAbove": 90
  }
}
```

**Configuration Options:**
- `enabled` — Master switch for the entire system
- `maxQueueSize` — Maximum items in queue (drops lowest priority when full)
- `minComplexityToQueue` — Don't queue simple tasks below this complexity
- `idleCheckIntervalMs` — How often to check for idle backends (30s recommended)
- `preferredBackend` — First choice for refinement ("claudeCode")
- `fallbackBackend` — Backup if preferred is unavailable ("codex")
- `maxRefinementsPerHour` — Rate limiting to prevent expensive backend overuse
- `skipIfOriginalScoreAbove` — Don't refine if original scored this high (0-100)

## API Methods

### Core Methods

**`enqueue(taskResult)`** — Add completed task to refinement queue
- Returns: `{queued: boolean, queueItem?: object, reason?: string}`
- Checks eligibility, calculates priority, respects queue size limits

**`getNextRefinement()`** — Get highest priority pending item  
- Returns: `QueueItem | null`
- Used by idle checker to pick what to refine next

**`startRefinement(id, backend)`** — Mark item as in-progress
- Returns: `{success: boolean, error?: string}`
- Records which backend picked up the item + timestamp

**`completeRefinement(id, result, improvementScore)`** — Finish refinement
- Returns: `{success: boolean, error?: string}` 
- Moves item to completed, updates statistics

**`skipRefinement(id, reason)`** — Skip refinement (original was good enough)
- Returns: `{success: boolean, error?: string}`
- Moves to completed with skip status

### Monitoring Methods  

**`getStats()`** — Return queue statistics
```json
{
  "totalRefined": 42,
  "avgImprovementScore": 73.5, 
  "tokensSaved": 125000,
  "queueLength": 8,
  "completedCount": 42,
  "refinementsThisHour": 3,
  "remainingThisHour": 2
}
```

**`getQueue()`** — Return current queue state
```json
{
  "pending": [...],
  "inProgress": [...], 
  "recent": [...]  // Last 10 completed
}
```

**`checkIdleAndRefine()`** — The core periodic check
- Returns: `{processed: boolean, reason: string, nextItem?: object, prompt?: string}`
- Checks rate limits, finds next item, builds refinement prompt
- NOTE: Actual backend execution integration required

## Integration Points

### 1. Task Completion Hook

In `index.js`, after a task completes on a cheap backend:

```javascript
// After task completion (around line 280)
if (result.success && ['local', 'api'].includes(backend)) {
  const refinementQueue = require('./refinement-queue');
  const queueResult = refinementQueue.enqueue({
    taskId: taskId,
    description: task.description,
    backend: backend,
    model: task.model,
    complexity: task.complexity,
    type: task.type,
    result: result,
    tokens: result.tokens || 0,
    duration: result.duration || 0,
    qualityScore: result.qualityScore
  });
  
  if (queueResult.queued) {
    console.log(`[ROUTER] Queued task ${taskId} for refinement (priority ${queueResult.queueItem.priority})`);
  }
}
```

### 2. Idle Check Timer

In `index.js` or a dedicated scheduler, add periodic checking:

```javascript
// Set up refinement queue checker
const refinementQueue = require('./refinement-queue');

setInterval(async () => {
  try {
    const checkResult = await refinementQueue.checkIdleAndRefine();
    
    if (checkResult.nextItem && checkResult.processed === false) {
      // Backend integration needed here
      // Check if Claude Code or Codex is actually idle
      // If so, execute the refinement task
      
      const { nextItem, prompt } = checkResult;
      
      // TODO: Integrate with actual backend idle checking
      // TODO: Execute refinement task with the generated prompt
      // TODO: Call completeRefinement() with results
    }
  } catch (error) {
    console.error('[ROUTER] Refinement queue check failed:', error.message);
  }
}, refinementQueue.getInstance().config.idleCheckIntervalMs);
```

### 3. Dashboard API Endpoints

Add to `dashboard-server.js` (documentation only):

```javascript
// GET /api/refinement-queue — List pending items
app.get('/api/refinement-queue', (req, res) => {
  const refinementQueue = require('./refinement-queue');
  res.json(refinementQueue.getQueue());
});

// GET /api/refinement-stats — Queue statistics  
app.get('/api/refinement-stats', (req, res) => {
  const refinementQueue = require('./refinement-queue');
  res.json(refinementQueue.getStats());
});

// POST /api/refinement/:id/skip — Manually skip an item
app.post('/api/refinement/:id/skip', (req, res) => {
  const refinementQueue = require('./refinement-queue');
  const { reason = 'Manual skip' } = req.body;
  const result = refinementQueue.skipRefinement(req.params.id, reason);
  res.json(result);
});

// POST /api/refinement/:id/prioritize — Bump priority  
app.post('/api/refinement/:id/prioritize', (req, res) => {
  const refinementQueue = require('./refinement-queue');
  // Implementation needed: modify queue item priority
  res.json({success: false, error: 'Not implemented'});
});
```

## Benefits

### Immediate Benefits
- **Faster user responses** — cheap models respond immediately
- **Better quality over time** — expensive models improve outputs when idle  
- **Cost efficiency** — expensive tokens only used when spare capacity
- **Zero latency impact** — refinement happens asynchronously

### Long-term Benefits  
- **Performance insights** — measure which model combinations work best
- **Quality metrics** — track how much refinement actually helps
- **Adaptive learning** — skip refinement for model/task combinations that don't improve
- **Capacity planning** — understand when expensive backends are truly idle

### Strategic Benefits
- **Competitive advantage** — fast response + high quality
- **Budget optimization** — maximize value from expensive model subscriptions  
- **Quality assurance** — automatic code review for all generated outputs
- **User satisfaction** — best of both worlds (speed + quality)

## Future Enhancements

### Phase 2: Smart Learning
- Track improvement patterns by task type and model combination
- Auto-skip refinement for combinations that rarely improve
- Dynamic priority adjustment based on historical improvement scores

### Phase 3: Multi-stage Refinement
- Chain refinements: Haiku → Sonnet → Opus for very complex tasks
- Specialized refinement models for different task types
- Cross-model validation and consensus scoring

### Phase 4: User Preference Integration
- Per-user quality vs speed preferences
- Optional real-time refinement for premium users
- Quality confidence scoring with user feedback loops

## Monitoring & Debugging

### Key Metrics to Track
- Queue length over time
- Average improvement scores by model combination
- Refinement completion rate
- Cost savings from fast-first approach
- Backend idle time utilization

### Troubleshooting
- **Queue growing too large** → Increase `maxRefinementsPerHour` or check backend availability
- **Low improvement scores** → Review refinement prompts, check model selection
- **Backends never idle** → Adjust idle detection logic, review task routing
- **High cost from refinements** → Tighten `minComplexityToQueue` or reduce rate limits

## Testing

The system includes comprehensive tests covering:
1. Task enqueueing with eligibility rules
2. Priority calculation and ordering  
3. Queue size management and overflow handling
4. Refinement lifecycle (start → complete → skip)
5. Statistics calculation and accuracy
6. Rate limiting and idle checking logic
7. Configuration override behavior
8. Error handling and edge cases

Run tests: `node test.js` (includes refinement queue section)

## Conclusion

The Quality Refinement Queue transforms the OpenClaw Task Router from a simple model router into an intelligent **quality optimization system**. By implementing the junior/senior developer pattern, we achieve the holy grail of AI systems: **fast response times with high-quality outputs**, all while optimizing costs and learning from every interaction.

This system positions OpenClaw as a next-generation AI router that doesn't just route requests — it actively improves them over time.